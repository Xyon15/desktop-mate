# ğŸ’¬ Guide Rapide : Chat Engine (Phase 5)

**Utilisation du moteur conversationnel de Kira**

---

## ğŸš€ DÃ©marrage Rapide

### 1. Initialisation Simple

```python
from src.ai.chat_engine import ChatEngine

# Initialisation (charge config par dÃ©faut)
engine = ChatEngine()

# Charger le modÃ¨le LLM
engine.model_manager.load_model()

# PrÃªt Ã  discuter !
```

### 2. PremiÃ¨re Conversation

```python
# Envoyer un message
response = engine.chat(
    user_input="Bonjour Kira, prÃ©sente-toi !",
    user_id="desktop_user",
    source="desktop"
)

# Afficher la rÃ©ponse
print(f"ğŸ¤– Kira : {response.response}")
print(f"ğŸ­ Ã‰motion : {response.emotion}")
print(f"â±ï¸ Temps : {response.processing_time:.2f}s")
print(f"ğŸ“ Tokens : {response.tokens_used}")
```

---

## ğŸ¯ Utilisation AvancÃ©e

### Pattern Singleton

```python
from src.ai.chat_engine import get_chat_engine

# RÃ©cupÃ¨re l'instance globale (singleton)
engine = get_chat_engine()

# MÃªme instance partout dans l'application
engine2 = get_chat_engine()
assert engine is engine2  # True
```

### Conversation Multi-Utilisateurs

```python
# Utilisateur 1
response1 = engine.chat(
    user_input="Salut Kira !",
    user_id="user_alice",
    source="desktop"
)

# Utilisateur 2
response2 = engine.chat(
    user_input="Hello Kira !",
    user_id="user_bob",
    source="discord"
)

# Historiques sÃ©parÃ©s automatiquement !
```

### Gestion Contexte

```python
# Conversation avec contexte
for message in ["Bonjour", "Comment Ã§a va ?", "Parle-moi de toi"]:
    response = engine.chat(message, "user123", "desktop")
    print(f"User: {message}")
    print(f"Kira: {response.response}\n")
    # Historique gÃ©rÃ© automatiquement !
```

---

## ğŸ­ DÃ©tection Ã‰motions

### Ã‰motions DÃ©tectables

Le ChatEngine dÃ©tecte automatiquement 6 Ã©motions :

| Ã‰motion | Mots-clÃ©s Exemples | Blendshape VRM |
|---------|-------------------|----------------|
| `joy` | content, heureux, gÃ©nial, ğŸ˜Š | Joy |
| `angry` | Ã©nervÃ©, colÃ¨re, agacÃ©, ğŸ˜  | Angry |
| `sorrow` | triste, dommage, dÃ©solÃ©, ğŸ˜¢ | Sorrow |
| `surprised` | wow, incroyable, ğŸ˜² | Surprised |
| `fun` | drÃ´le, lol, haha, ğŸ˜‚ | Fun |
| `neutral` | ok, bien, alors | Neutral |

### Test Manuel DÃ©tecteur

```python
from src.ai.chat_engine import EmotionDetector

detector = EmotionDetector()

# Test
phrases = [
    "Je suis super content ! ğŸ˜Š",
    "C'est Ã©nervant...",
    "Tristement..."
]

for phrase in phrases:
    emotion = detector.analyze(phrase)
    print(f"{phrase} â†’ {emotion}")
```

---

## âš™ï¸ Configuration

### Profils GPU

Le ChatEngine utilise les profils GPU de la config :

```python
from src.ai.config import get_config

config = get_config()

# Voir profil actuel
print(config.gpu_profile)  # "balanced" par dÃ©faut

# Changer profil
config.switch_profile("performance")

# Recharger modÃ¨le avec nouveau profil
engine.model_manager.unload_model()
engine.model_manager.load_model()
```

### ParamÃ¨tres GÃ©nÃ©ration

```python
# Modifier config avant gÃ©nÃ©ration
config = get_config()
config.temperature = 0.8  # Plus crÃ©atif
config.max_tokens = 256   # RÃ©ponses plus courtes
config.top_p = 0.95       # Sampling plus large

# La prochaine gÃ©nÃ©ration utilisera ces valeurs
response = engine.chat("Raconte-moi une blague !", "user123")
```

---

## ğŸ“Š Statistiques

### Stats Globales

```python
stats = engine.get_stats()

# Stats mÃ©moire
print(stats['memory']['total_interactions'])
print(stats['memory']['unique_users'])

# Stats modÃ¨le
print(stats['model']['is_loaded'])
print(stats['model']['gpu_info'])

# Config active
print(stats['config']['gpu_profile'])
```

### Stats Utilisateur

```python
# Via la mÃ©moire directement
user_stats = engine.memory.get_user_stats("user123")

print(f"Messages : {user_stats['total_interactions']}")
print(f"Ã‰motions : {user_stats['emotions']}")
```

---

## ğŸ—‘ï¸ Gestion Historique

### Effacer Historique Utilisateur

```python
# Effacer tout l'historique d'un utilisateur
deleted = engine.clear_user_history("user123")
print(f"{deleted} interactions supprimÃ©es")

# Effacer seulement une source
deleted = engine.clear_user_history("user123", source="discord")
```

### Effacer Tout

```python
# Via la mÃ©moire
engine.memory.clear_all_history()
```

---

## ğŸ”§ Debugging

### VÃ©rifier Ã‰tat

```python
# Ã‰tat du modÃ¨le
print(f"ModÃ¨le chargÃ© : {engine.model_manager.is_loaded}")

# Info GPU
gpu_info = engine.model_manager.detect_gpu()
if gpu_info and gpu_info.available:
    print(f"GPU : {gpu_info.name}")
    vram_gb = gpu_info.vram_total / (1024**3)
    print(f"VRAM : {vram_gb:.1f} GB")

# Historique
history = engine.memory.get_history("user123", limit=5)
print(f"{len(history)} messages en historique")
```

### Logs

```python
import logging

# Activer logs debug
logging.basicConfig(level=logging.DEBUG)

# Maintenant tous les logs sont visibles
response = engine.chat("Test", "user123")
```

---

## ğŸš¨ Gestion Erreurs

### ModÃ¨le Non ChargÃ©

```python
try:
    response = engine.chat("Hello", "user123")
except RuntimeError as e:
    print(f"Erreur : {e}")
    # Charger le modÃ¨le
    engine.model_manager.load_model()
    # RÃ©essayer
    response = engine.chat("Hello", "user123")
```

### GÃ©nÃ©ration Ã‰chouÃ©e

```python
try:
    response = engine.chat("Test trÃ¨s long..." * 1000, "user123")
except RuntimeError as e:
    print(f"GÃ©nÃ©ration Ã©chouÃ©e : {e}")
    # RÃ©duire taille input ou max_tokens
```

---

## ğŸ“ Format Prompt ChatML

Le ChatEngine utilise le format **ChatML** (Zephyr) :

```
<|system|>
[System prompt personnalisÃ© Kira]
</|system|>

<|user|>
Message historique 1
</|user|>
<|assistant|>
RÃ©ponse historique 1
</|assistant|>

<|user|>
Message historique 2
</|user|>
<|assistant|>
RÃ©ponse historique 2
</|assistant|>

<|user|>
Message actuel
</|user|>
<|assistant|>
```

Les balises `<|user|>` et `<|system|>` sont utilisÃ©es comme **stop sequences** pour arrÃªter la gÃ©nÃ©ration.

---

## ğŸ¯ Cas d'Usage

### 1. Interface Desktop (GUI)

```python
# main.py ou gui.py
from src.ai.chat_engine import get_chat_engine

class ChatWindow:
    def __init__(self):
        self.engine = get_chat_engine()
        self.engine.model_manager.load_model()
    
    def send_message(self, text):
        response = self.engine.chat(
            user_input=text,
            user_id="desktop_user",
            source="desktop"
        )
        
        # Afficher rÃ©ponse dans GUI
        self.display_message(response.response)
        
        # Mettre Ã  jour expression faciale
        self.update_avatar_emotion(response.emotion)
```

### 2. Bot Discord

```python
# discord_bot/bot.py
from src.ai.chat_engine import get_chat_engine

engine = get_chat_engine()
engine.model_manager.load_model()

@bot.event
async def on_message(message):
    if message.author == bot.user:
        return
    
    response = engine.chat(
        user_input=message.content,
        user_id=str(message.author.id),
        source="discord"
    )
    
    await message.channel.send(response.response)
```

### 3. Tests Unitaires

```python
# tests/test_my_feature.py
from unittest.mock import Mock
from src.ai.chat_engine import ChatEngine

def test_my_feature():
    # Mock le ModelManager
    mock_manager = Mock()
    mock_manager.is_loaded = True
    mock_manager.generate.return_value = "Bonjour !"
    
    engine = ChatEngine(model_manager=mock_manager)
    
    response = engine.chat("Test", "user123")
    assert response.response == "Bonjour !"
```

---

## âœ… Checklist DÃ©ploiement

Avant d'utiliser le ChatEngine en production :

- [ ] **ModÃ¨le LLM** : `models/zephyr-7b-beta.Q5_K_M.gguf` prÃ©sent
- [ ] **Config** : `data/config.json` avec section `"ai"` configurÃ©e
- [ ] **Base de donnÃ©es** : `data/chat_history.db` accessible (crÃ©Ã©e auto)
- [ ] **GPU** : Drivers NVIDIA Ã  jour (si GPU utilisÃ©)
- [ ] **Profil GPU** : AdaptÃ© Ã  VRAM disponible (balanced = 3-4GB)
- [ ] **Tests** : `pytest tests/test_chat_engine.py` passe (23/23)

---

## ğŸ”— Liens Utiles

- **README Session 10** : `docs/sessions/session_10_ai_chat/README.md`
- **Config IA** : `src/ai/config.py`
- **Model Manager** : `src/ai/model_manager.py`
- **MÃ©moire** : `src/ai/memory.py`
- **Tests** : `tests/test_chat_engine.py`
- **Test IntÃ©gration** : `tests/test_integration_phase5.py`

---

**ğŸ‰ Kira est prÃªte Ã  discuter ! ğŸ’¬**
