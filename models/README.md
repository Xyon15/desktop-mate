# Mod√®les LLM pour Desktop-Mate (Kira)

Ce dossier contient les mod√®les de langage (LLM) utilis√©s par Kira.

## üì¶ Mod√®le Actuel

**`zephyr-7b-beta.Q5_K_M.gguf`**
- Taille : 6.8 GB
- Format : GGUF (llama.cpp compatible)
- Quantification : Q5_K_M (bon √©quilibre qualit√©/taille)
- Source : Mistral 7B fine-tun√©

## üì• Installation

### M√©thode 1 : Copie depuis Kira-Bot (recommand√©e)

```bash
# PowerShell
Copy-Item "C:\Dev\IA-chatbot\models\zephyr-7b-beta.Q5_K_M.gguf" "C:\Dev\desktop-mate\models\"
```

### M√©thode 2 : T√©l√©chargement direct

Si le fichier n'existe pas dans Kira-Bot, t√©l√©chargez-le depuis Hugging Face :

```bash
# URL : https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF
# Fichier : zephyr-7b-beta.Q5_K_M.gguf (6.8 GB)
```

## ‚ö†Ô∏è Important

**Ce dossier est dans `.gitignore` !**

Les mod√®les LLM sont trop volumineux pour Git (6+ GB).
- ‚úÖ Ils doivent √™tre copi√©s/t√©l√©charg√©s manuellement
- ‚ùå Ne JAMAIS les commit dans Git

## üéØ Utilisation

Le mod√®le est charg√© automatiquement par `ModelManager` :
- Chemin configur√© dans `data/config.json` ‚Üí `ai.model_path`
- D√©tection GPU automatique
- Profils d'optimisation adaptatifs (Performance, Balanced, CPU Fallback)

## üîÑ Changer de Mod√®le

Pour utiliser un autre mod√®le :

1. T√©l√©charger/copier le nouveau mod√®le dans `models/`
2. Modifier `data/config.json` :
   ```json
   {
     "ai": {
       "model_path": "models/nouveau_modele.gguf"
     }
   }
   ```
3. Red√©marrer Desktop-Mate

## üìä Mod√®les Compatibles

Tous les mod√®les GGUF sont compatibles :
- Zephyr 7B (recommand√©)
- Mistral 7B
- Phi-2 (plus petit, plus rapide)
- Llama 2/3 (diverses tailles)

**Crit√®re** : Taille < VRAM disponible (RTX 4050 = 6 GB VRAM)
